{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from warnings import filterwarnings\n",
    "#filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"vehicles.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['id','vin', 'url', 'region_url', 'image_url', 'description', 'county', 'lat', 'long','size','paint_color','type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['region', 'price', 'year', 'manufacturer', 'model', 'condition',\n",
       "       'cylinders', 'fuel', 'odometer', 'title_status', 'transmission',\n",
       "       'drive', 'state'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "region           True\n",
       "price           False\n",
       "year            False\n",
       "manufacturer     True\n",
       "model            True\n",
       "condition        True\n",
       "cylinders        True\n",
       "fuel             True\n",
       "odometer        False\n",
       "title_status     True\n",
       "transmission     True\n",
       "drive            True\n",
       "size             True\n",
       "type             True\n",
       "paint_color      True\n",
       "state            True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical = df.dtypes == object\n",
    "categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.loc[:, df.columns != 'price'], df['price'], random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_preprocessing = make_pipeline(\n",
    "    SimpleImputer(strategy='constant'),\n",
    "    OneHotEncoder(handle_unknown='ignore'))\n",
    "cont_preprocessing = make_pipeline(\n",
    "    SimpleImputer(),\n",
    "    StandardScaler())\n",
    "preprocess = make_column_transformer(\n",
    "    (cat_preprocessing, make_column_selector(dtype_include='object')),\n",
    "    remainder=cont_preprocessing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.725155200002958"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lr = make_pipeline(preprocess, Ridge())\n",
    "scores = cross_val_score(pipe_lr, X_train, y_train, cv=5)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear model we picked is Ridge regression, and by the R2 score produced by the model we can conclude that the dataset fits very poorly on a linear model and we should explore other more complex models for this dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first clean the dataset by dropping rows with price equal to 0 for the purpose of this homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing outliers\n",
    "df_clean = df[df['price'] != 0]\n",
    "df_clean = df_clean[df_clean['price'] < 300000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_clean.iloc[:, df_clean.columns != 'price'], df_clean['price'], random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_oh_preprocessing = make_pipeline(\n",
    "    SimpleImputer(strategy='constant'),\n",
    "    OneHotEncoder(handle_unknown='ignore'))\n",
    "    \n",
    "cont_preprocessing = make_pipeline(\n",
    "    SimpleImputer(strategy='median'),\n",
    "    StandardScaler(),\n",
    "    PolynomialFeatures(degree=2))\n",
    "    \n",
    "preprocess = make_column_transformer(\n",
    "    (cat_preprocessing, make_column_selector(dtype_include='object')),\n",
    "    remainder=cont_preprocessing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = make_pipeline(preprocess, Ridge())\n",
    "scores = cross_val_score(pipe_lr, X_train, y_train, cv=5)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By cleaning the data (removing rows with price of 0) and other preprocessing techniques: 1. removing standardscaler, 2. changing the imputing strategy to be 'median' for continuous variables and 3. adding PolynomialFeatures of degree 2, the R2 score from cross validation increased significantly to close to 0. It is still a very bad score for the linear model, but we can see that in-depth preprocessing can improve the model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
